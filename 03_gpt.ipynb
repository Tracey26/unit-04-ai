{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** GPT2 Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 3.27Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:00, 1.47Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 9.18Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [05:34, 1.49Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 2.87Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 1.90Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 2.48Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "#gpt2.download_gpt2(\n",
    "    #model_name = '124M'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name='124M',reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unicorn jumped over a bed of flowers and into a bedroom with her mother.\n",
      "\n",
      "\"She's so cute,\" Mom said. \"It's like she's just sitting there with her hand on her head…in the corner, looking at a picture of her with that iconic blue eyes.\"\n",
      "\n",
      "She looked down and smiled wryly.\n",
      "\n",
      "\"I'm so sorry. I was really sad about this. My mother was really devastated, and I had just been kissing her in the bathroom when the unicorn came up to me and said, 'Hey, look at this picture! I'm sitting here with you.' I'm so sorry. I was really mad.\"\n",
      "\n",
      "\"I'm not mad,\" Mom said. \"I just wanted to say thank you.\"\n",
      "\n",
      "The unicorn ran off to her mother's bedroom and Mom whirled around. She saw the large, beautiful baby. She took it in her hand and hugged it tightly.\n",
      "\n",
      "\"You're such a good friend. That's so nice of you. I'm so glad you're okay. I'm so sorry for all of this. I just don't know how we can get to this point. I'm just so sorry, Mom. I burst out crying and I felt so great. I looked so happy, I could have cried and cried and cried and cried. I couldn't wait to meet you three days later and I had to be so happy. I was so happy. I couldn't wait to meet you three days later.\"\n",
      "\n",
      "Mom hugged the baby and hugged the unicorn. She hugged it for all her friends.\n",
      "\n",
      "\"I'm so sorry,\" Mom said. \"I'm so sorry that you're over it. I didn't cause you any pain. I didn't cause you any pain. I just wanted to say thank you. I wanted to say thank you to everyone. I'll be so happy to meet you three days later.\"\n",
      "\n",
      "Mom's heart thumped in her chest.\n",
      "\n",
      "\"I'm so sorry, Mom. I mean, I don't know how I can help you. I'm so sorry to hear that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset. I'm so sorry that you're going to be so upset.\n",
      "\n",
      "Mom hugged the unicorn. She hugged it for all her friends.\n",
      "\n",
      "\"I'm so sorry,\" Mom said. \"I had to be so sorry. I didn't cause you any pain. I didn't cause you any pain. I just wanted to say thank you.\"\n",
      "\n",
      "\"I'm so sorry,\" Mom said. \"I was so sorry. I didn't cause you any pain. I didn't cause you any pain. I just wanted to say thank you.\"\n",
      "\n",
      "Mom's eyes went wide.\n",
      "\n",
      "\"I'm so sorry,\" Mom said. \"I mean, I was so sorry\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(session,prefix ='The unicorn jumped over a bed of flowers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547157.157069 1922799 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 20.24] loss=4.21 avg=4.21\n",
      "[2 | 40.64] loss=3.97 avg=4.09\n",
      "[3 | 60.61] loss=3.82 avg=4.00\n",
      "[4 | 79.78] loss=3.69 avg=3.92\n",
      "[5 | 98.81] loss=3.73 avg=3.88\n",
      "[6 | 118.05] loss=3.50 avg=3.82\n",
      "[7 | 136.93] loss=3.81 avg=3.82\n",
      "[8 | 155.67] loss=3.62 avg=3.79\n",
      "[9 | 174.59] loss=3.59 avg=3.77\n",
      "[10 | 193.26] loss=3.60 avg=3.75\n",
      "[11 | 211.45] loss=3.36 avg=3.71\n",
      "[12 | 229.48] loss=3.44 avg=3.69\n",
      "[13 | 246.99] loss=3.55 avg=3.68\n",
      "[14 | 264.71] loss=3.63 avg=3.67\n",
      "[15 | 282.29] loss=3.56 avg=3.67\n",
      "[16 | 300.29] loss=3.47 avg=3.65\n",
      "[17 | 317.78] loss=3.41 avg=3.64\n",
      "[18 | 335.15] loss=3.53 avg=3.63\n",
      "[19 | 353.64] loss=3.50 avg=3.62\n",
      "[20 | 372.18] loss=3.37 avg=3.61\n",
      "[21 | 390.46] loss=3.45 avg=3.60\n",
      "[22 | 408.27] loss=3.49 avg=3.60\n",
      "[23 | 425.80] loss=3.42 avg=3.59\n",
      "[24 | 443.17] loss=3.47 avg=3.58\n",
      "[25 | 460.29] loss=3.46 avg=3.58\n",
      "[26 | 477.34] loss=3.46 avg=3.57\n",
      "[27 | 494.64] loss=3.61 avg=3.57\n",
      "[28 | 512.23] loss=3.20 avg=3.56\n",
      "[29 | 530.04] loss=3.55 avg=3.56\n",
      "[30 | 549.17] loss=3.31 avg=3.55\n",
      "[31 | 567.71] loss=3.37 avg=3.54\n",
      "[32 | 586.10] loss=3.61 avg=3.54\n",
      "[33 | 604.07] loss=3.38 avg=3.54\n",
      "[34 | 621.71] loss=3.53 avg=3.54\n",
      "[35 | 639.08] loss=3.46 avg=3.53\n",
      "[36 | 656.81] loss=3.45 avg=3.53\n",
      "[37 | 674.39] loss=3.38 avg=3.53\n",
      "[38 | 693.01] loss=3.51 avg=3.53\n",
      "[39 | 711.73] loss=3.55 avg=3.53\n",
      "[40 | 730.14] loss=3.53 avg=3.53\n",
      "[41 | 749.34] loss=3.53 avg=3.53\n",
      "[42 | 768.85] loss=3.36 avg=3.52\n",
      "[43 | 789.67] loss=3.44 avg=3.52\n",
      "[44 | 809.71] loss=3.29 avg=3.51\n",
      "[45 | 828.76] loss=3.24 avg=3.51\n",
      "[46 | 847.57] loss=3.25 avg=3.50\n",
      "[47 | 866.68] loss=3.41 avg=3.50\n",
      "[48 | 885.48] loss=2.95 avg=3.48\n",
      "[49 | 904.60] loss=3.34 avg=3.48\n",
      "[50 | 922.75] loss=3.44 avg=3.48\n",
      "[51 | 940.44] loss=3.33 avg=3.47\n",
      "[52 | 958.40] loss=3.40 avg=3.47\n",
      "[53 | 976.12] loss=3.34 avg=3.47\n",
      "[54 | 993.74] loss=3.53 avg=3.47\n",
      "[55 | 1012.51] loss=3.22 avg=3.46\n",
      "[56 | 1030.50] loss=2.96 avg=3.45\n",
      "[57 | 1049.60] loss=3.26 avg=3.45\n",
      "[58 | 1068.10] loss=3.41 avg=3.45\n",
      "[59 | 1086.37] loss=3.20 avg=3.44\n",
      "[60 | 1105.63] loss=3.19 avg=3.44\n",
      "[61 | 1125.00] loss=3.25 avg=3.43\n",
      "[62 | 1143.58] loss=3.32 avg=3.43\n",
      "[63 | 1161.50] loss=3.33 avg=3.43\n",
      "[64 | 1179.39] loss=3.14 avg=3.42\n",
      "[65 | 1198.04] loss=3.12 avg=3.42\n",
      "[66 | 1215.76] loss=3.09 avg=3.41\n",
      "[67 | 1233.35] loss=3.12 avg=3.40\n",
      "[68 | 1251.56] loss=3.17 avg=3.40\n",
      "[69 | 1269.61] loss=3.28 avg=3.40\n",
      "[70 | 1287.81] loss=3.18 avg=3.39\n",
      "[71 | 1305.89] loss=3.21 avg=3.39\n",
      "[72 | 1324.89] loss=3.35 avg=3.39\n",
      "[73 | 1343.23] loss=3.35 avg=3.39\n",
      "[74 | 1361.81] loss=3.04 avg=3.38\n",
      "[75 | 1381.30] loss=3.30 avg=3.38\n",
      "[76 | 1399.75] loss=3.04 avg=3.37\n",
      "[77 | 1418.76] loss=3.12 avg=3.37\n",
      "[78 | 1437.35] loss=3.38 avg=3.37\n",
      "[79 | 1455.58] loss=3.17 avg=3.36\n",
      "[80 | 1474.09] loss=2.98 avg=3.36\n",
      "[81 | 1493.00] loss=3.01 avg=3.35\n",
      "[82 | 1511.21] loss=3.47 avg=3.35\n",
      "[83 | 1529.56] loss=3.28 avg=3.35\n",
      "[84 | 1549.64] loss=3.22 avg=3.35\n",
      "[85 | 1570.84] loss=3.29 avg=3.35\n",
      "[86 | 1591.24] loss=3.35 avg=3.35\n",
      "[87 | 1611.14] loss=3.50 avg=3.35\n",
      "[88 | 1630.42] loss=2.99 avg=3.34\n",
      "[89 | 1649.77] loss=3.33 avg=3.34\n",
      "[90 | 1669.41] loss=3.19 avg=3.34\n",
      "[91 | 1688.30] loss=3.11 avg=3.34\n",
      "[92 | 1707.04] loss=3.37 avg=3.34\n",
      "[93 | 1727.14] loss=3.10 avg=3.33\n",
      "[94 | 1747.18] loss=3.39 avg=3.34\n",
      "[95 | 1765.90] loss=3.20 avg=3.33\n",
      "[96 | 1784.80] loss=3.10 avg=3.33\n",
      "[97 | 1803.58] loss=3.23 avg=3.33\n",
      "[98 | 1822.16] loss=3.41 avg=3.33\n",
      "[99 | 1839.98] loss=3.08 avg=3.33\n",
      "[100 | 1859.86] loss=3.17 avg=3.32\n",
      "Saving checkpoint/shakespeare/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    'shakespeare.txt',\n",
    "    model_name = '124M',\n",
    "    steps=100,\n",
    "    run_name='shakespeare'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You shall surrender!\n",
      "\n",
      "MARI:\n",
      "I do think I, sir, shall deliver thee to yonder tower.\n",
      "\n",
      "TRANIO:\n",
      "I do think I, sir!\n",
      "\n",
      "O, sir!\n",
      "\n",
      "MARI:\n",
      "I would not but do it; but I shall never know;\n",
      "Myself, for my worth, and my honour,\n",
      "To be consigned to your mercy.\n",
      "\n",
      "TRANIO:\n",
      "I would not to see you; I would not, sir.\n",
      "\n",
      "MARI:\n",
      "Why, you would not, to see you.\n",
      "\n",
      "TRANIO:\n",
      "Well, but to see you.\n",
      "\n",
      "MARI:\n",
      "No, sir, you would not, to see you; you would not, to see you.\n",
      "\n",
      "TRANIO:\n",
      "I would not, to see you; I would not, to see you.\n",
      "\n",
      "MARI:\n",
      "But how, by God, and on what ground, sir,\n",
      "I do think I shall be consigned to yonder tower,\n",
      "As my honour and my honour, that I may\n",
      "visit you, and be consigned to your mercy,\n",
      "I have not thought of it.\n",
      "\n",
      "TRANIO:\n",
      "I would not, to see you; I would not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "But how, by God, and on what ground, sir,\n",
      "I do think I shall be consigned to yonder tower,\n",
      "As my honour and my honour, that I may\n",
      "visit you, and be consigned to your mercy;\n",
      "I have not thought of it.\n",
      "\n",
      "MARI:\n",
      "You must be consigned to your mercy, sir; and you must be\n",
      "consigned to my mercy.\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "Nor shall I, sir; but you shall be consigned to your mercy\n",
      "If I may be consigned to your mercy.\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "TRANIO:\n",
      "I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "Why, now, I will not, to see you; I will not, to see you.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "What, then, then, now, then?\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "Must I, must I, must I, must I, must I?\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "What, then, then, then?\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I never thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO:\n",
      "I have thought of it.\n",
      "\n",
      "MARI:\n",
      "\n",
      "TRANIO\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2,\n",
    "    prefix=\"You shall surrender!\",\n",
    "    run_name='shakespeare'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
